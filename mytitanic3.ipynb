{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Toolkit for Splunk - Notebook for TensorFlow 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network for Binary Classification\n",
    "This notebook contains an example workflow how to work on custom containerized code that seamlessly interfaces with the Deep Learning Toolkit for Splunk. As an example we use a custom binary neural network classifier built on keras and tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: By default every time you save this notebook the cells are exported into a python module which is then invoked by Splunk MLTK commands like <code> | fit ... | apply ... | summary </code>. Please read the Model Development Guide in the Deep Learning Toolkit app for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 0 - import libraries\n",
    "At stage 0 we define all imports necessary to run our subsequent code depending on various libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "name": "mltkc_import"
   },
   "outputs": [],
   "source": [
    "# mltkc_import\n",
    "# this definition exposes all python module imports that should be available in all subsequent commands\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# global constants\n",
    "MODEL_DIRECTORY = \"/srv/app/model/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 1.18.1\n",
      "pandas version: 1.0.1\n",
      "TensorFlow version: 2.1.0\n",
      "Keras version: 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing purposes\n",
    "print(\"numpy version: \" + np.__version__)\n",
    "print(\"pandas version: \" + pd.__version__)\n",
    "print(\"TensorFlow version: \" + tf.__version__)\n",
    "print(\"Keras version: \" + keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1 - get a data sample from Splunk\n",
    "In Splunk run a search to pipe a prepared dataset into this environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| inputlookup  titanic-train.csv\n",
    "| fit Imputer Age strategy=mean | eval Age = round(Imputed_Age / 90,1)  | fields - Imputed_Age\n",
    "| search Embarked = * \n",
    "| eval SibSp = case(SibSp=0,\"S0\", SibSp=1,\"S1\", SibSp=2,\"S2\", SibSp=3,\"S3\", SibSp=4,\"S4\", SibSp=5,\"S5\",1=1,\"S_More\")\n",
    "| eval Parch = case(Parch=0,\"P0\", Parch=1,\"P1\", Parch=2,\"P2\", Parch=3,\"P3\", Parch=4,\"P4\", Parch=5,\"P5\",1=1,\"P_More\")\n",
    "| eventstats max(Fare) as max_Fare\n",
    "| eval Fare =  round(Fare/max_Fare,1) | eval Fare = \"F_\" + Fare, Age = \"Age_\" + Age  | fields - max_Fare\n",
    "| rex field=Name \"\\,\\s(?<title>\\w+)\"  | fields - Name \n",
    "| eval title = case(title=\"Mr\",\"Mr\", title=\"Miss\", \"Miss\", title=\"Mrs\",\"Mrs\",title=\"Master\",\"Mastar\",1=1,\"Other\")\n",
    "| rex field=Ticket \"(?<TicketNo>\\d+)$\" | fields - Ticket\n",
    "| bin TicketNo span=100000\n",
    "| eval TicketNo = case(TicketNo=\"0-100000\",\"No0\", TicketNo=\"100000-200000\", \"No100000\", TicketNo=\"200000-300000\", \"No200000\",TicketNo=\"300000-400000\",\"No300000\",1=1,\"NoOther\")\n",
    "| rex field=Cabin \"(?<Cabin>\\w)\" \n",
    "| eval Cabin = case(Cabin=\"T\",\"Cabin_Unknown\",Cabin=\"C\",\"Cabin_C\", isnull(Cabin),\"Cabin_Unknown\",1=1,Cabin)\n",
    "| eval {Pclass} = 1, {Sex} = 1, {Embarked} =1, {title}=1, {Cabin} = 1, {TicketNo}=1, {SibSp}=1,{Parch}=1, {Fare} =1, {Age} = 1\n",
    "| fillnull\n",
    "| fields - Pclass, Sex, Embarked, title, count, Cabin, TicketNo, Fare, SibSp, Parch,Age, PassengerId, \"Age_0.9\"\n",
    "| fit MLTKContainer mode=stage algo=mytitanic3 Survived from * into app:mytitanic3_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you run this search your data set sample is available as a csv inside the container to develop your model. The name is taken from the into keyword (\"my_model\" in the example above) or set to \"default\" if no into keyword is present. This step is intended to work with a subset of your data to create your custom model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "name": "mltkc_stage"
   },
   "outputs": [],
   "source": [
    "# mltkc_stage\n",
    "# this cell is not executed from MLTK and should only be used for staging data into the notebook environment\n",
    "def stage(name):\n",
    "    with open(\"data/\"+name+\".csv\", 'r') as f:\n",
    "        df = pd.read_csv(f)\n",
    "    with open(\"data/\"+name+\".json\", 'r') as f:\n",
    "        param = json.load(f)\n",
    "    return df, param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  3  male  S  Mr  Cabin_Unknown  No0  S1  P0  F_0.0  ...  S2  S5  \\\n",
      "0         0  1     1  1   1              1    1   1   1      1  ...   0   0   \n",
      "\n",
      "   F  P3  Age_0.8  S_More  P4  F_1.0  F_0.4  P_More  \n",
      "0  0   0        0       0   0      0      0       0  \n",
      "\n",
      "[1 rows x 57 columns]\n",
      "(889, 57)\n",
      "{'options': {'params': {'mode': 'stage', 'algo': 'mytitanic3'}, 'args': ['Survived', '*'], 'target_variable': ['Survived'], 'feature_variables': ['*'], 'model_name': 'mytitanic3_model', 'algo_name': 'MLTKContainer', 'mlspl_limits': {'handle_new_cat': 'default', 'max_distinct_cat_values': '100', 'max_distinct_cat_values_for_classifiers': '100', 'max_distinct_cat_values_for_scoring': '100', 'max_fit_time': '600', 'max_inputs': '100000', 'max_memory_usage_mb': '1000', 'max_model_size_mb': '15', 'max_score_time': '600', 'streaming_apply': 'false', 'use_sampling': 'true'}, 'kfold_cv': None}, 'feature_variables': ['3', 'male', 'S', 'Mr', 'Cabin_Unknown', 'No0', 'S1', 'P0', 'F_0.0', 'Age_0.2', '1', 'female', 'C', 'Mrs', 'Cabin_C', 'F_0.1', 'Age_0.4', 'Miss', 'NoOther', 'S0', 'Age_0.3', 'No100000', 'No300000', 'Q', 'E', 'Age_0.6', 'Mastar', 'S3', 'P1', 'Age_0.0', 'P2', '2', 'No200000', 'G', 'P5', 'S4', 'D', 'A', 'Age_0.1', 'F_0.5', 'Other', 'B', 'F_0.3', 'Age_0.7', 'F_0.2', 'Age_0.5', 'S2', 'S5', 'F', 'P3', 'Age_0.8', 'S_More', 'P4', 'F_1.0', 'F_0.4', 'P_More'], 'target_variables': ['Survived']}\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing purposes\n",
    "df, param = stage(\"mytitanic3_model\")\n",
    "print(df[0:1])\n",
    "print(df.shape)\n",
    "print(str(param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>3</th>\n",
       "      <th>male</th>\n",
       "      <th>S</th>\n",
       "      <th>Mr</th>\n",
       "      <th>Cabin_Unknown</th>\n",
       "      <th>No0</th>\n",
       "      <th>S1</th>\n",
       "      <th>P0</th>\n",
       "      <th>F_0.0</th>\n",
       "      <th>...</th>\n",
       "      <th>S2</th>\n",
       "      <th>S5</th>\n",
       "      <th>F</th>\n",
       "      <th>P3</th>\n",
       "      <th>Age_0.8</th>\n",
       "      <th>S_More</th>\n",
       "      <th>P4</th>\n",
       "      <th>F_1.0</th>\n",
       "      <th>F_0.4</th>\n",
       "      <th>P_More</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>889 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  3  male  S  Mr  Cabin_Unknown  No0  S1  P0  F_0.0  ...  S2  S5  \\\n",
       "0           0  1     1  1   1              1    1   1   1      1  ...   0   0   \n",
       "1           1  0     0  0   0              0    1   1   1      0  ...   0   0   \n",
       "2           1  1     0  1   0              1    0   0   1      1  ...   0   0   \n",
       "3           1  0     0  1   0              0    0   1   1      0  ...   0   0   \n",
       "4           0  1     1  1   1              1    0   0   1      1  ...   0   0   \n",
       "..        ... ..   ... ..  ..            ...  ...  ..  ..    ...  ...  ..  ..   \n",
       "884         0  0     1  1   0              1    0   0   1      1  ...   0   0   \n",
       "885         1  0     0  1   0              0    0   0   1      0  ...   0   0   \n",
       "886         0  1     0  1   0              1    1   1   0      1  ...   0   0   \n",
       "887         1  0     1  0   1              0    0   0   1      0  ...   0   0   \n",
       "888         0  1     1  0   1              1    0   0   1      1  ...   0   0   \n",
       "\n",
       "     F  P3  Age_0.8  S_More  P4  F_1.0  F_0.4  P_More  \n",
       "0    0   0        0       0   0      0      0       0  \n",
       "1    0   0        0       0   0      0      0       0  \n",
       "2    0   0        0       0   0      0      0       0  \n",
       "3    0   0        0       0   0      0      0       0  \n",
       "4    0   0        0       0   0      0      0       0  \n",
       "..  ..  ..      ...     ...  ..    ...    ...     ...  \n",
       "884  0   0        0       0   0      0      0       0  \n",
       "885  0   0        0       0   0      0      0       0  \n",
       "886  0   0        0       0   0      0      0       0  \n",
       "887  0   0        0       0   0      0      0       0  \n",
       "888  0   0        0       0   0      0      0       0  \n",
       "\n",
       "[889 rows x 57 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2 - create and initialize a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "name": "mltkc_init"
   },
   "outputs": [],
   "source": [
    "# mltkc_init\n",
    "# initialize the model\n",
    "# params: data and parameters\n",
    "# returns the model object which will be used as a reference to call fit, apply and summary subsequently\n",
    "def init(df,param):            \n",
    "    X = df[param['feature_variables']]\n",
    "    print(\"FIT build model with input shape \" + str(X.shape))\n",
    "    input_shape = int(X.shape[1])\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(input_shape*2, input_dim=input_shape, activation=tf.nn.relu,\n",
    "                                kernel_initializer='random_uniform'))\n",
    "    model.add(keras.layers.Dense(32, activation=tf.nn.relu))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    model.add(keras.layers.Dense(32, activation=tf.nn.relu))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    model.add(keras.layers.Dense(32, activation=tf.nn.relu))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    model.add(keras.layers.Dense(32, activation=tf.nn.relu))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    model.add(keras.layers.Dense(32, activation=tf.nn.relu))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    model.add(keras.layers.Dense(32, activation=tf.nn.relu))\n",
    "    model.add(keras.layers.Dense(32, activation=tf.nn.relu))\n",
    "    model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIT build model with input shape (889, 56)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 112)               6384      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                3616      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 17,009\n",
      "Trainable params: 16,689\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# test mltkc_stage_create_model\n",
    "model = init(df,param)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889, 57)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3 - fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "name": "mltkc_fit"
   },
   "outputs": [],
   "source": [
    "# mltkc_stage_create_model_fit\n",
    "# returns a fit info json object\n",
    "def fit(model,df,param):\n",
    "    returns = {}            \n",
    "    X = df[param['feature_variables']]\n",
    "    Y = df[param['target_variables']]\n",
    "    \n",
    "    X_train, X_val = np.vsplit(X, [int(X.shape[0] * 0.8)])\n",
    "    Y_train, Y_val = np.vsplit(Y, [int(Y.shape[0] * 0.8)])\n",
    "    \n",
    "    model_epochs = 300\n",
    "    model_batch_size = 10\n",
    "    if 'options' in param:\n",
    "        if 'params' in param['options']:\n",
    "            if 'epochs' in param['options']['params']:\n",
    "                model_epochs = int(param['options']['params']['epochs'])\n",
    "            if 'batch_size' in param['options']['params']:\n",
    "                model_batch_size = int(param['options']['params']['batch_size'])\n",
    "    # connect model training to tensorboard\n",
    "    log_dir=\"/srv/notebooks/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, embeddings_freq=1)\n",
    "    \n",
    "    # Early Stopping\n",
    "    earlystopping_callback= tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=20, verbose=0, mode='auto')\n",
    "    \n",
    "    # run the training\n",
    "    returns['fit_history'] = model.fit(x=X_train,\n",
    "                                       y=Y_train, \n",
    "                                       verbose=2, \n",
    "                                       epochs=model_epochs, \n",
    "                                       batch_size=model_batch_size, \n",
    "                                       validation_data=(X_val, Y_val),\n",
    "                                       callbacks=[tensorboard_callback,earlystopping_callback])\n",
    "    # memorize parameters\n",
    "    returns['model_epochs'] = model_epochs\n",
    "    returns['model_batch_size'] = model_batch_size\n",
    "    returns['model_loss_acc'] = model.evaluate(x = X, y = Y)\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 711 samples, validate on 178 samples\n",
      "Epoch 1/300\n",
      "711/711 - 2s - loss: 0.7014 - accuracy: 0.5443 - val_loss: 0.6760 - val_accuracy: 0.6461\n",
      "Epoch 2/300\n",
      "711/711 - 0s - loss: 0.6967 - accuracy: 0.5387 - val_loss: 0.6599 - val_accuracy: 0.6461\n",
      "Epoch 3/300\n",
      "711/711 - 0s - loss: 0.6791 - accuracy: 0.5992 - val_loss: 0.6539 - val_accuracy: 0.6461\n",
      "Epoch 4/300\n",
      "711/711 - 0s - loss: 0.6790 - accuracy: 0.5879 - val_loss: 0.6508 - val_accuracy: 0.6461\n",
      "Epoch 5/300\n",
      "711/711 - 0s - loss: 0.6636 - accuracy: 0.5992 - val_loss: 0.6266 - val_accuracy: 0.6461\n",
      "Epoch 6/300\n",
      "711/711 - 0s - loss: 0.6536 - accuracy: 0.6245 - val_loss: 0.6304 - val_accuracy: 0.6461\n",
      "Epoch 7/300\n",
      "711/711 - 0s - loss: 0.6387 - accuracy: 0.6596 - val_loss: 0.5941 - val_accuracy: 0.6461\n",
      "Epoch 8/300\n",
      "711/711 - 0s - loss: 0.6291 - accuracy: 0.6568 - val_loss: 0.5402 - val_accuracy: 0.7191\n",
      "Epoch 9/300\n",
      "711/711 - 0s - loss: 0.5928 - accuracy: 0.6906 - val_loss: 0.5222 - val_accuracy: 0.7528\n",
      "Epoch 10/300\n",
      "711/711 - 0s - loss: 0.6158 - accuracy: 0.6962 - val_loss: 0.4901 - val_accuracy: 0.8090\n",
      "Epoch 11/300\n",
      "711/711 - 0s - loss: 0.6053 - accuracy: 0.7032 - val_loss: 0.4797 - val_accuracy: 0.8034\n",
      "Epoch 12/300\n",
      "711/711 - 0s - loss: 0.5901 - accuracy: 0.6990 - val_loss: 0.4518 - val_accuracy: 0.7978\n",
      "Epoch 13/300\n",
      "711/711 - 0s - loss: 0.5803 - accuracy: 0.7131 - val_loss: 0.4883 - val_accuracy: 0.7865\n",
      "Epoch 14/300\n",
      "711/711 - 0s - loss: 0.5595 - accuracy: 0.7286 - val_loss: 0.4776 - val_accuracy: 0.7753\n",
      "Epoch 15/300\n",
      "711/711 - 0s - loss: 0.5672 - accuracy: 0.7286 - val_loss: 0.4674 - val_accuracy: 0.7753\n",
      "Epoch 16/300\n",
      "711/711 - 0s - loss: 0.5542 - accuracy: 0.7384 - val_loss: 0.4712 - val_accuracy: 0.7809\n",
      "Epoch 17/300\n",
      "711/711 - 0s - loss: 0.5642 - accuracy: 0.7637 - val_loss: 0.4635 - val_accuracy: 0.7978\n",
      "Epoch 18/300\n",
      "711/711 - 0s - loss: 0.5291 - accuracy: 0.7595 - val_loss: 0.4483 - val_accuracy: 0.7978\n",
      "Epoch 19/300\n",
      "711/711 - 0s - loss: 0.5232 - accuracy: 0.7693 - val_loss: 0.4544 - val_accuracy: 0.7921\n",
      "Epoch 20/300\n",
      "711/711 - 0s - loss: 0.5251 - accuracy: 0.7567 - val_loss: 0.4494 - val_accuracy: 0.7921\n",
      "Epoch 21/300\n",
      "711/711 - 0s - loss: 0.5270 - accuracy: 0.7553 - val_loss: 0.4500 - val_accuracy: 0.7921\n",
      "Epoch 22/300\n",
      "711/711 - 0s - loss: 0.5102 - accuracy: 0.7862 - val_loss: 0.4560 - val_accuracy: 0.8034\n",
      "Epoch 23/300\n",
      "711/711 - 0s - loss: 0.5028 - accuracy: 0.8003 - val_loss: 0.4376 - val_accuracy: 0.8090\n",
      "Epoch 24/300\n",
      "711/711 - 0s - loss: 0.4927 - accuracy: 0.7947 - val_loss: 0.4354 - val_accuracy: 0.8146\n",
      "Epoch 25/300\n",
      "711/711 - 0s - loss: 0.5178 - accuracy: 0.7764 - val_loss: 0.4464 - val_accuracy: 0.8146\n",
      "Epoch 26/300\n",
      "711/711 - 0s - loss: 0.5040 - accuracy: 0.7693 - val_loss: 0.4237 - val_accuracy: 0.8371\n",
      "Epoch 27/300\n",
      "711/711 - 0s - loss: 0.5083 - accuracy: 0.7665 - val_loss: 0.4240 - val_accuracy: 0.8371\n",
      "Epoch 28/300\n",
      "711/711 - 0s - loss: 0.5163 - accuracy: 0.7693 - val_loss: 0.4241 - val_accuracy: 0.8427\n",
      "Epoch 29/300\n",
      "711/711 - 0s - loss: 0.4990 - accuracy: 0.7989 - val_loss: 0.4210 - val_accuracy: 0.8483\n",
      "Epoch 30/300\n",
      "711/711 - 0s - loss: 0.4808 - accuracy: 0.8017 - val_loss: 0.4171 - val_accuracy: 0.8315\n",
      "Epoch 31/300\n",
      "711/711 - 0s - loss: 0.4914 - accuracy: 0.7848 - val_loss: 0.4170 - val_accuracy: 0.8202\n",
      "Epoch 32/300\n",
      "711/711 - 0s - loss: 0.4783 - accuracy: 0.8045 - val_loss: 0.3983 - val_accuracy: 0.8371\n",
      "Epoch 33/300\n",
      "711/711 - 0s - loss: 0.4785 - accuracy: 0.8101 - val_loss: 0.3960 - val_accuracy: 0.8483\n",
      "Epoch 34/300\n",
      "711/711 - 0s - loss: 0.4748 - accuracy: 0.7918 - val_loss: 0.4004 - val_accuracy: 0.8427\n",
      "Epoch 35/300\n",
      "711/711 - 0s - loss: 0.5095 - accuracy: 0.7679 - val_loss: 0.3959 - val_accuracy: 0.8539\n",
      "Epoch 36/300\n",
      "711/711 - 0s - loss: 0.4767 - accuracy: 0.8143 - val_loss: 0.3916 - val_accuracy: 0.8539\n",
      "Epoch 37/300\n",
      "711/711 - 0s - loss: 0.4861 - accuracy: 0.7876 - val_loss: 0.3916 - val_accuracy: 0.8652\n",
      "Epoch 38/300\n",
      "711/711 - 0s - loss: 0.4799 - accuracy: 0.7961 - val_loss: 0.4141 - val_accuracy: 0.8427\n",
      "Epoch 39/300\n",
      "711/711 - 0s - loss: 0.4766 - accuracy: 0.7932 - val_loss: 0.3902 - val_accuracy: 0.8483\n",
      "Epoch 40/300\n",
      "711/711 - 0s - loss: 0.4664 - accuracy: 0.8073 - val_loss: 0.3701 - val_accuracy: 0.8708\n",
      "Epoch 41/300\n",
      "711/711 - 0s - loss: 0.4699 - accuracy: 0.8017 - val_loss: 0.3658 - val_accuracy: 0.8596\n",
      "Epoch 42/300\n",
      "711/711 - 0s - loss: 0.4771 - accuracy: 0.8172 - val_loss: 0.3911 - val_accuracy: 0.8483\n",
      "Epoch 43/300\n",
      "711/711 - 0s - loss: 0.4636 - accuracy: 0.8045 - val_loss: 0.3954 - val_accuracy: 0.8427\n",
      "Epoch 44/300\n",
      "711/711 - 0s - loss: 0.4195 - accuracy: 0.8368 - val_loss: 0.3889 - val_accuracy: 0.8371\n",
      "Epoch 45/300\n",
      "711/711 - 0s - loss: 0.4602 - accuracy: 0.7975 - val_loss: 0.3898 - val_accuracy: 0.8427\n",
      "Epoch 46/300\n",
      "711/711 - 0s - loss: 0.4689 - accuracy: 0.8087 - val_loss: 0.3928 - val_accuracy: 0.8371\n",
      "Epoch 47/300\n",
      "711/711 - 0s - loss: 0.4759 - accuracy: 0.7932 - val_loss: 0.3899 - val_accuracy: 0.8483\n",
      "Epoch 48/300\n",
      "711/711 - 0s - loss: 0.4544 - accuracy: 0.8186 - val_loss: 0.3856 - val_accuracy: 0.8483\n",
      "Epoch 49/300\n",
      "711/711 - 0s - loss: 0.4570 - accuracy: 0.8214 - val_loss: 0.3881 - val_accuracy: 0.8427\n",
      "Epoch 50/300\n",
      "711/711 - 0s - loss: 0.4631 - accuracy: 0.8115 - val_loss: 0.3970 - val_accuracy: 0.8483\n",
      "Epoch 51/300\n",
      "711/711 - 0s - loss: 0.4694 - accuracy: 0.8059 - val_loss: 0.3951 - val_accuracy: 0.8258\n",
      "889/889 [==============================] - 0s 35us/sample - loss: 0.3931 - accuracy: 0.8583\n",
      "[0.3930839549905136, 0.8582677]\n"
     ]
    }
   ],
   "source": [
    "returns = fit(model,df,param)\n",
    "print(returns['model_loss_acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 4 - apply the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "name": "mltkc_apply"
   },
   "outputs": [],
   "source": [
    "# mltkc_stage_create_model_apply\n",
    "def apply(model,df,param):\n",
    "    X = df[param['feature_variables']]\n",
    "    y_hat = model.predict(x = X, verbose=0)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test mltkc_stage_create_model_apply\n",
    "y_hat = apply(model,df,param)\n",
    "#print(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 5 - save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "name": "mltkc_save"
   },
   "outputs": [],
   "source": [
    "# save model to name in expected convention \"<algo_name>_<model_name>.h5\"\n",
    "def save(model,name):\n",
    "    # save keras model to hdf5 file\n",
    "    # https://www.tensorflow.org/beta/tutorials/keras/save_and_restore_models\n",
    "    model.save(MODEL_DIRECTORY + name + \".h5\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 6 - load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "name": "mltkc_load"
   },
   "outputs": [],
   "source": [
    "# load model from name in expected convention \"<algo_name>_<model_name>.h5\"\n",
    "def load(name):\n",
    "    model = keras.models.load_model(MODEL_DIRECTORY + name + \".h5\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 7 - provide a summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "name": "mltkc_summary"
   },
   "outputs": [],
   "source": [
    "# return model summary\n",
    "def summary(model=None):\n",
    "    returns = {\"version\": {\"tensorflow\": tf.__version__, \"keras\": keras.__version__} }\n",
    "    if model is not None:\n",
    "        # Save keras model summary to string:\n",
    "        s = []\n",
    "        model.summary(print_fn=lambda x: s.append(x+'\\n'))\n",
    "        returns[\"summary\"] = ''.join(s)\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Stages\n",
    "All subsequent cells are not tagged and can be used for further freeform code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit SPL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| inputlookup  titanic-train.csv\n",
    "| fit Imputer Age strategy=mean | eval Age = round(Imputed_Age / 90,1)  | fields - Imputed_Age\n",
    "| search Embarked = * \n",
    "| eval SibSp = case(SibSp=0,\"S0\", SibSp=1,\"S1\", SibSp=2,\"S2\", SibSp=3,\"S3\", SibSp=4,\"S4\", SibSp=5,\"S5\",1=1,\"S_More\")\n",
    "| eval Parch = case(Parch=0,\"P0\", Parch=1,\"P1\", Parch=2,\"P2\", Parch=3,\"P3\", Parch=4,\"P4\", Parch=5,\"P5\",1=1,\"P_More\")\n",
    "| eventstats max(Fare) as max_Fare\n",
    "| eval Fare =  round(Fare/max_Fare,1) | eval Fare = \"F_\" + Fare, Age = \"Age_\" + Age  | fields - max_Fare\n",
    "| rex field=Name \"\\,\\s(?<title>\\w+)\"  | fields - Name \n",
    "| eval title = case(title=\"Mr\",\"Mr\", title=\"Miss\", \"Miss\", title=\"Mrs\",\"Mrs\",title=\"Master\",\"Mastar\",1=1,\"Other\")\n",
    "| rex field=Ticket \"(?<TicketNo>\\d+)$\" | fields - Ticket\n",
    "| bin TicketNo span=100000\n",
    "| eval TicketNo = case(TicketNo=\"0-100000\",\"No0\", TicketNo=\"100000-200000\", \"No100000\", TicketNo=\"200000-300000\", \"No200000\",TicketNo=\"300000-400000\",\"No300000\",1=1,\"NoOther\")\n",
    "| rex field=Cabin \"(?<Cabin>\\w)\" \n",
    "| eval Cabin = case(Cabin=\"T\",\"Cabin_Unknown\",Cabin=\"C\",\"Cabin_C\", isnull(Cabin),\"Cabin_Unknown\",1=1,Cabin)\n",
    "| eval {Pclass} = 1, {Sex} = 1, {Embarked} =1, {title}=1, {Cabin} = 1, {TicketNo}=1, {SibSp}=1,{Parch}=1, {Fare} =1, {Age} = 1\n",
    "| fillnull\n",
    "| fields - Pclass, Sex, Embarked, title, count, Cabin, TicketNo, Fare, SibSp, Parch,Age, PassengerId, \"Age_0.9\"\n",
    "| fit MLTKContainer algo=mytitanic3 Survived from * into app:mytitanic3_model\n",
    "| eval predict = if(predicted_Survived > 0.5 , 1,0) \n",
    "| score f1_score Survived against predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply SPL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| inputlookup  titanic-test.csv\n",
    "| fit Imputer Age strategy=mean | eval Age = round(Imputed_Age / 90,1)  | fields - Imputed_Age\n",
    "| search Embarked = * \n",
    "| eval SibSp = case(SibSp=0,\"S0\", SibSp=1,\"S1\", SibSp=2,\"S2\", SibSp=3,\"S3\", SibSp=4,\"S4\", SibSp=5,\"S5\",1=1,\"S_More\")\n",
    "| eval Parch = case(Parch=0,\"P0\", Parch=1,\"P1\", Parch=2,\"P2\", Parch=3,\"P3\", Parch=4,\"P4\", Parch=5,\"P5\",1=1,\"P_More\")\n",
    "| eventstats max(Fare) as max_Fare\n",
    "| eval Fare =  round(Fare/max_Fare,1) | eval Fare = \"F_\" + Fare, Age = \"Age_\" + Age  | fields - max_Fare\n",
    "| rex field=Name \"\\,\\s(?<title>\\w+)\"  | fields - Name \n",
    "| eval title = case(title=\"Mr\",\"Mr\", title=\"Miss\", \"Miss\", title=\"Mrs\",\"Mrs\",title=\"Master\",\"Mastar\",1=1,\"Other\")\n",
    "| rex field=Ticket \"(?<TicketNo>\\d+)$\" | fields - Ticket\n",
    "| bin TicketNo span=100000\n",
    "| eval TicketNo = case(TicketNo=\"0-100000\",\"No0\", TicketNo=\"100000-200000\", \"No100000\", TicketNo=\"200000-300000\", \"No200000\",TicketNo=\"300000-400000\",\"No300000\",1=1,\"NoOther\")\n",
    "| rex field=Cabin \"(?<Cabin>\\w)\" \n",
    "| eval Cabin = case(Cabin=\"T\",\"Cabin_Unknown\",Cabin=\"C\",\"Cabin_C\", isnull(Cabin),\"Cabin_Unknown\",1=1,Cabin)\n",
    "| eval {Pclass} = 1, {Sex} = 1, {Embarked} =1, {title}=1, {Cabin} = 1, {TicketNo}=1, {SibSp}=1,{Parch}=1, {Fare} =1, {Age} = 1\n",
    "| fillnull\n",
    "| fields - Pclass, Sex, Embarked, title, count, Cabin, TicketNo, Fare, SibSp, Parch,Age\n",
    "| apply app:mytitanic3_model \n",
    "| eval Survived = if(predicted_Survived > 0.5 , 1,0) \n",
    "| table PassengerId Survived"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
